\section{Algorytm Gonzalez'a}

Pierwszy algorytm, który opiszemy to \textit{Farthest point algorithm} z pracy \cite{Gonzalez1985ClusteringTM}.
Jest to pierwszy algorytm aproksymacyjny rozwiązująych problem k-centrów z błędem nie większem niż $2 \cdot OPT$, gdzie \textit{OPT} to optymalne rozwiązanie.
Jego złożoność to $O(nk)$, gdzie $n$ to liczba punktów danych na wejściu. 
\\~\\
Na potrzeby tego rozdziału wprowadzimy kilka definicji.

\begin{definition}
    Niech \emph{G = (V, E, W)} będzie ważonym nieskierowanym grafem ze zbiorem wierzchołków $V$, krawędzi $E$ oraz funkcją $W: E \rightarrow \mathbb{R}^{+}$ przyporządkowującą wagi krawędziom. 
    W tym rozdziale utożsamiamy wagi z dystansem pomiędzy dwoma punktami. 
\end{definition}

\begin{definition}
    Podział zbioru wierzchołków na k zbiorów $B_{1},\dots,B_{k}$, nazywamy \emph{k-split}.
\end{definition}

\begin{definition}
    Zbiory $B_{i}$ podziału k-split nazywamy \emph{klastrami}.
\end{definition}

\noindent
Dla każdego k-splitu defninujemy funkcję celu $f: B_{1},\dots,B_{k} \rightarrow \mathbb{R}^{+}$.
W tym rozdziale zakładamy, że funkcją celu to $max(M_{1},\dots,M_{k})$, gdzie $M_{i}$ to największa waga krawędzi pomiędzy dowolnymi dwoma punktami z $B_{i}$.

\begin{definition}
    \emph{Problem klastrowania.} Dla danego grafu $G$, funkcji celu $f$ oraz $k \in \mathbb{N}^{+}$ znaleźć k-split dla którego funkcja $f$ jest zminimalizowana.
    Dla przykładu: znaleźć k-split $(B_{1}^{*},\dots,B_{k}^{*})$ taki, że 
    \begin{equation}
        f(B_{1}^{*},\dots,B_{k}^{*}) = min\{ f(B_{1},\dots,B_{k}) | (B_{1},\dots,B_{k}) \text{ to k-split dla G } \}
    \end{equation}
\end{definition}

\noindent
Niech $S \subset \mathbb{R}^{d}$ to bedzie zbiór, który chcemy sklastrować oraz niech $T$ będzie podzbiorem $S$.
Zakładamy, że $|S| > k$ ponieważ w przeciwnym przypadku problem jest trywialnie rozwiązywalny.
\begin{definition}
Zbiór $T$ nazywamy $(k+1)$ kliką wysokości $h$ jeżeli moc zbioru $T$ jest równa $k+1$ oraz odległość pomiędzy parą dwóch rożnych punktów jest równa co najmniej $h$. 
\end{definition}

\noindent
Niech $OPT(S)$ oznacza optymalne rozwiązanie problemu k-centrów dla zbioru $S$.
Udowodnimy teraz następujący lemat, który jest potrzebny w dowodzie ograniczającym błąd aproksymacji algorytmu.

\begin{lemma}
    Jeżeli w zbiorze $S$ istnieje $(k+1)$ klika wysokości $h$, to $OPT(S) \geq h$.
\end{lemma}

\begin{proof}
    Wartość funkcji celu dla kliki wysokości $h$ to conajmniej $h$ ponieważ kilka ma $k+1$ elementów więc $2$ z nich wylądują w jednym klastrze.
    W takim razie waga krawędzi pomiędzy tymi punktami to conajmniej $h$ co implikuje, że $OPT(S) > h$.
\end{proof}

\noindent
Algorytm składa się z fazy inicjalizującej oraz $k-1$ faz powiększających.
W fazie inicjalizującej wszystkie elementy są przypisana do zbioru $B_{1}$, który jest pierwszym klasterm.
Jeden z elementów tego zbioru oznaczamy jako $(t_{1})$ - środek klastra $B_{1}$.
Wybór tego elementu jest losowy.
Podczas $j$ fazy powiększającej, niektóre elementy z istniejącego podziału na klastry $B_{1}, \dots, B_{j}$ trafiają do nowego zbioru $B_{j+1}$.
Dodatkowo jeden z elemntów nowego zbioru będzie oznaczony jako $(t_{j+1})$ - środek klastra $B_{j+1}$.
Budowę zbioru $B_{j+1}$ rozpoczynamy od wyboru punktu $v$, który należy do jednego ze zbiorów $B_{1}, \dots, B_{j}$ oraz odległość do centrum jego akutalnego klastra jest największa spośród wszystkich punktów. 
Taki punkt będzie oznaczony jako $(t_{j+1})$, czyli jest centerm klastra $B_{j+1}$.
Każdy punkt dla którego dystans do $v$ jest nie większy niż dystans do centra klastu w którym się znajduje zostaje przeniesiony do $B_{j+1}$.
\begin{algorithm}
    \caption{}
\begin{algorithmic}
    \State Dla każdego punkt $\notin T$, algorytm trzyma $neighbor(p)$, czyli najbliższy punkt w $T$ oraz $dist(p)$, czyli dystans od $p$ do $neighbor(P)$.
    \Procedure{Farthest point algorithm}{}
        \State $T \leftarrow \emptyset$
        \State $dist(p) \leftarrow \inf$ for all $p \in S$
        \While{$|T| \leq k$}                    
            \State $D \leftarrow max\{dist(p) | p \in S-T\}$
            \State wybierz $v$ z $S-T$ tak, aby $dist(v) = D$
            \State add $v$ to T
            \State zaktualizuj $neighbor(p)$ oraz $dist(p)$ dla każdego $p \in S-T$
        \EndWhile
    \EndProcedure
    \Return $T$
\end{algorithmic}
\end{algorithm}
\\
Taki algorytmy buduje jakiś k-split.
Teraz pokażemy, że dla takiego k-splitu wartość funkcji celu jest ograniczona przez $2OPT(S)$.
\\~\\
Niech $v \in B_{j}$ oraz $1 \leq j \leq k$ będzie wierzchołkiem którego odległość do $(t_{j})$ jest maksymalna.
Niech $h$ będzie tą odległością.
Ponieważ dla zbioru wag krawędzi zachodzi nierówność trójkąta to:
\begin{equation}
    W(E(x, y)) \leq W(E(x, t_{i})) + W(E(y, t_{i})) \leq 2h
\end{equation}
gdzie $t_{i}$ to centrum klastra dla punktów $x, y \in B_{i}$.
A więc możemy ograniczyć wartość naszej funkcji celu przez $\leq 2h$.
Ponieważ $v$ nigdy nie zostało wybrane na centrum klastra to wiemy, że $W(t_{i}, t_{j}) \geq h$ dla $i \neq j$.
Niech $T = \{ t_{1}, \dots, t_{k}, v \}$.
Z definicji wiemy, że $T$ jest $(k+1)$ kliką wagi $h$ więc z lematu 2 $OPT(S) \geq h$.
A więc ograniczenie wartości funkcji celu to $\leq 2h \leq 2OPT(S)$.